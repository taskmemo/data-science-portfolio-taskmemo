## todo list
- [ ] ローカルLLMのモデル選定
| 優先度                           | モデル名               | 特徴                                    | 理由 |
| :---------------------------- | :----------------- | :------------------------------------ | :- |
| 🥇 **`mistral:instruct`（7B）** | 高速・軽量・英日バランス良      | M4のCPU/GPUでも余裕。会話・推薦文生成が自然。DSPyとの相性◎  |    |
| 🥈 **`llama3:8b-instruct`**   | 精度・流暢さ・指示順守性がさらに良い | 24GBメモリで動作可能（やや遅くなるが実用範囲）。多言語に強く自然。   |    |
| 🥉 **`phi3:mini`（3.8B）**      | 超軽量で速い             | 試作やモバイル開発用に最適。ただし文生成は少し硬い。            |    |
| 🎌 **`elyza:7b-instruct`**    | 日本語最適化             | 完全日本語対応。カフェBotが日本語メインなら有力候補。M4上でも実行可。 |    |

- [☑️] .env, config.yamlの設定
- [☑️] google_maps.pyの実装
- [ ] Streamlit.pyによる実装
- [ ] DSPyの実装
- [] ローカルLLMで自然文章の生成